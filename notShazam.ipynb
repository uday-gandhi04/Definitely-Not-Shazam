{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64351864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from scipy.ndimage import maximum_filter, gaussian_filter\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load audio\n",
    "y, sr = librosa.load('songs\\\\Run It Up - (Raag.Fm).mp3', sr=None)\n",
    "\n",
    "# Step 2: Compute STFT\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "S_mag = np.abs(S)\n",
    "\n",
    "# Step 3: Smooth spectrogram (optional, helps with noisy peaks)\n",
    "S_smooth = gaussian_filter(S_mag, sigma=1.0)\n",
    "\n",
    "# Step 4: 2D local maxima detection\n",
    "neighborhood_size = 20\n",
    "local_max = maximum_filter(S_smooth, size=neighborhood_size) == S_smooth\n",
    "\n",
    "# Step 5: Apply a threshold to keep only strong peaks\n",
    "threshold = np.percentile(S_smooth[local_max], 95)  # keep top 5%\n",
    "peak_mask = local_max & (S_smooth >= threshold)\n",
    "\n",
    "# Step 6: Get peak coordinates (freq_bin, time_bin)\n",
    "peak_indices = np.argwhere(peak_mask)\n",
    "\n",
    "# Step 7: Convert to time (sec) and frequency (Hz)\n",
    "peak_freqs = peak_indices[:, 0] * (sr / n_fft)\n",
    "peak_times = peak_indices[:, 1] * (hop_length / sr)\n",
    "\n",
    "# Combine for (time, freq) tuples\n",
    "constellation_map = list(zip(peak_times, peak_freqs))\n",
    "\n",
    "# Print few peaks\n",
    "print(\"Sample Peaks (time sec, frequency Hz):\")\n",
    "print(constellation_map[:10])\n",
    "\n",
    "# Optional: Visualize peaks on spectrogram\n",
    "\"\"\"plt.figure(figsize=(12, 6))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S_mag, ref=np.max),\n",
    "                         sr=sr, hop_length=hop_length, x_axis='time', y_axis='hz')\n",
    "plt.scatter(peak_times, peak_freqs, marker='x', color='red', s=10, label='Peaks')\n",
    "plt.title('Spectral Peaks (Constellation Map)')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "from scipy.ndimage import maximum_filter, gaussian_filter\n",
    "\n",
    "# Step 1: Load audio\n",
    "y, sr = librosa.load('songs\\\\Run It Up - (Raag.Fm).mp3', sr=None)\n",
    "\n",
    "# Step 2: Compute STFT\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "S_mag = np.abs(S)\n",
    "\n",
    "# Step 3: Smooth spectrogram (optional, helps with noisy peaks)\n",
    "S_smooth = gaussian_filter(S_mag, sigma=1.0)\n",
    "\n",
    "# Step 4: 2D local maxima detection\n",
    "neighborhood_size = 20\n",
    "local_max = maximum_filter(S_smooth, size=neighborhood_size) == S_smooth\n",
    "\n",
    "# Step 5: Apply a threshold to keep only strong peaks\n",
    "threshold = np.percentile(S_smooth[local_max], 95)  # keep top 5%\n",
    "peak_mask = local_max & (S_smooth >= threshold)\n",
    "\n",
    "# Step 6: Get peak coordinates (freq_bin, time_bin)\n",
    "peak_indices = np.argwhere(peak_mask)\n",
    "\n",
    "# Step 7: Convert to time (sec) and frequency (Hz)\n",
    "peak_freqs = peak_indices[:, 0] * (sr / n_fft)\n",
    "peak_times = peak_indices[:, 1] * (hop_length / sr)\n",
    "\n",
    "# Combine for (time, freq) tuples\n",
    "constellation_map = list(zip(peak_times, peak_freqs))\n",
    "\n",
    "# Print few peaks\n",
    "print(\"Sample Peaks (time sec, frequency Hz):\")\n",
    "print(constellation_map[:10])\n",
    "\n",
    "# Optional: Visualize peaks on spectrogram\n",
    "\"\"\"plt.figure(figsize=(12, 6))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S_mag, ref=np.max),\n",
    "                         sr=sr, hop_length=hop_length, x_axis='time', y_axis='hz')\n",
    "plt.scatter(peak_times, peak_freqs, marker='x', color='red', s=10, label='Peaks')\n",
    "plt.title('Spectral Peaks (Constellation Map)')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.legend()\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf005d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Generate hashes\\nfingerprints = generate_hashes(constellation_map)\\n\\n# Show some hashes\\nprint(\"Sample Fingerprints (hash, time):\")\\nfor h in fingerprints[:10]:\\n    print(h)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_hashes(peaks, fan_value=5):\n",
    "    \"\"\"\n",
    "    Generate landmark hashes from peaks.\n",
    "    Each hash is made from (freq1, freq2, delta_time), anchored at time1.\n",
    "    \"\"\"\n",
    "    hashes = []\n",
    "    peaks = sorted(peaks)  # Sort by time\n",
    "\n",
    "    for i in range(len(peaks)):\n",
    "        t1, f1 = peaks[i]\n",
    "\n",
    "        for j in range(1, fan_value + 1):\n",
    "            if i + j < len(peaks):\n",
    "                t2, f2 = peaks[i + j]\n",
    "\n",
    "                delta_t = t2 - t1\n",
    "                if 0 < delta_t <= 5.0:  # Limit max time delta for compact hashes\n",
    "                    # Create hash string\n",
    "                    hash_str = f\"{int(f1)}|{int(f2)}|{int(delta_t * 100)}\"\n",
    "                    h = hashlib.sha1(hash_str.encode('utf-8')).hexdigest()[0:20]  # Shorten for space\n",
    "                    hashes.append((h, t1))  # Store hash + anchor time\n",
    "\n",
    "    return hashes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5424f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udayg\\AppData\\Local\\Temp\\ipykernel_11228\\82423531.py:8: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(song[\"location\"], sr=None)\n",
      "c:\\Users\\udayg\\OneDrive\\Desktop\\NotShazam\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('songs_meta.json', 'r', encoding='utf-8') as f:\n",
    "    songsMeta = json.load(f)\n",
    "\n",
    "hashIndex={}\n",
    "for song in songsMeta.values():\n",
    "    y, sr = librosa.load(song[\"location\"], sr=None)\n",
    "\n",
    "    # Step 2: Compute STFT\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_mag = np.abs(S)\n",
    "\n",
    "    # Step 3: Smooth spectrogram (optional, helps with noisy peaks)\n",
    "    S_smooth = gaussian_filter(S_mag, sigma=1.0)\n",
    "\n",
    "    # Step 4: 2D local maxima detection\n",
    "    neighborhood_size = 20\n",
    "    local_max = maximum_filter(S_smooth, size=neighborhood_size) == S_smooth\n",
    "\n",
    "    # Step 5: Apply a threshold to keep only strong peaks\n",
    "    threshold = np.percentile(S_smooth[local_max], 95)  # keep top 5%\n",
    "    peak_mask = local_max & (S_smooth >= threshold)\n",
    "\n",
    "    # Step 6: Get peak coordinates (freq_bin, time_bin)\n",
    "    peak_indices = np.argwhere(peak_mask)\n",
    "\n",
    "    # Step 7: Convert to time (sec) and frequency (Hz)\n",
    "    peak_freqs = peak_indices[:, 0] * (sr / n_fft)\n",
    "    peak_times = peak_indices[:, 1] * (hop_length / sr)\n",
    "\n",
    "    # Combine for (time, freq) tuples\n",
    "    constellation_map = list(zip(peak_times, peak_freqs))\n",
    "\n",
    "    #get fingerprints\n",
    "    fingerprint = generate_hashes(constellation_map)\n",
    "\n",
    "    for h,t in fingerprint:\n",
    "        if h not in hashIndex:\n",
    "            hashIndex[h]=[(song[\"title\"],t)]\n",
    "        else:\n",
    "            hashIndex[h].append((song[\"title\"], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f7b8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchSong(songLocation):\n",
    "    \"\"\"\n",
    "    Search for a song by title and artist.\n",
    "    Returns the fingerprints if found, else None.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(songLocation, sr=None)\n",
    "\n",
    "    # Step 2: Compute STFT\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_mag = np.abs(S)\n",
    "\n",
    "    # Step 3: Smooth spectrogram (optional, helps with noisy peaks)\n",
    "    S_smooth = gaussian_filter(S_mag, sigma=1.0)\n",
    "\n",
    "    # Step 4: 2D local maxima detection\n",
    "    neighborhood_size = 20\n",
    "    local_max = maximum_filter(S_smooth, size=neighborhood_size) == S_smooth\n",
    "\n",
    "    # Step 5: Apply a threshold to keep only strong peaks\n",
    "    threshold = np.percentile(S_smooth[local_max], 95)  # keep top 5%\n",
    "    peak_mask = local_max & (S_smooth >= threshold)\n",
    "\n",
    "    # Step 6: Get peak coordinates (freq_bin, time_bin)\n",
    "    peak_indices = np.argwhere(peak_mask)\n",
    "\n",
    "    # Step 7: Convert to time (sec) and frequency (Hz)\n",
    "    peak_freqs = peak_indices[:, 0] * (sr / n_fft)\n",
    "    peak_times = peak_indices[:, 1] * (hop_length / sr)\n",
    "\n",
    "    # Combine for (time, freq) tuples\n",
    "    constellation_map = list(zip(peak_times, peak_freqs))\n",
    "\n",
    "    #get fingerprints\n",
    "    fingerprint = generate_hashes(constellation_map)\n",
    "    score={\n",
    "    }\n",
    "    for h,t_query in fingerprint:\n",
    "        if h in hashIndex:\n",
    "            for (song,t_db) in hashIndex[h]:\n",
    "                delta= round(t_db-t_query, 2)\n",
    "                score[(song,delta)] = score.get((song,delta), 0) + 1\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "\n",
    "    for (song, delta), count in score.items():\n",
    "        if best_match is None or count > best_score:\n",
    "            best_match = song\n",
    "            best_score = count\n",
    "    print(songsMeta[best_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "746f7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'RAWAL x Bharg x Encore ABJ - MAGAN', 'artist': 'Rawal', 'location': 'songs\\\\RAWAL x Bharg x Encore ABJ - MAGAN.mp3'}\n"
     ]
    }
   ],
   "source": [
    "SearchSong(\"Testsongs\\\\abc.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88c65972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg\n",
      "[youtube:tab] PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] YouTube said: INFO - 1 unavailable video is hidden\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg: Redownloading playlist API JSON with unavailable videos\n",
      "[download] Downloading playlist: idk\n",
      "[youtube:tab] PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg page 1: Downloading API JSON\n",
      "[youtube:tab] Playlist idk: Downloading 5 items of 5\n",
      "[download] Downloading item 1 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=p0kKahGOKe8\n",
      "[youtube] p0kKahGOKe8: Downloading webpage\n",
      "[youtube] p0kKahGOKe8: Downloading tv client config\n",
      "[youtube] p0kKahGOKe8: Downloading player e12fbea4-main\n",
      "[youtube] p0kKahGOKe8: Downloading tv player API JSON\n",
      "[youtube] p0kKahGOKe8: Downloading ios player API JSON\n",
      "[youtube] p0kKahGOKe8: Downloading m3u8 information\n",
      "[info] p0kKahGOKe8: Downloading 1 format(s): 251\n",
      "[download] Destination: songs\\RAWAL x Bharg x Encore ABJ - MAGAN.webm\n",
      "[download] 100% of    3.38MiB in 00:00:02 at 1.68MiB/s   \n",
      "[ExtractAudio] Destination: songs\\RAWAL x Bharg x Encore ABJ - MAGAN.mp3\n",
      "Deleting original file songs\\RAWAL x Bharg x Encore ABJ - MAGAN.webm (pass -k to keep)\n",
      "[download] Downloading item 2 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=2k7E3u36gt4\n",
      "[youtube] 2k7E3u36gt4: Downloading webpage\n",
      "[youtube] 2k7E3u36gt4: Downloading tv client config\n",
      "[youtube] 2k7E3u36gt4: Downloading tv player API JSON\n",
      "[youtube] 2k7E3u36gt4: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 2k7E3u36gt4: Signature extraction failed: Some formats may be missing\n",
      "         player = https://www.youtube.com/s/player/e12fbea4/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] 2k7E3u36gt4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 2k7E3u36gt4: Downloading m3u8 information\n",
      "[info] Testing format 234\n",
      "[info] 2k7E3u36gt4: Downloading 1 format(s): 234\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 46\n",
      "[download] Destination: songs\\Khoya Sitara - Dizlaw (Official music video) ｜ Azadi Records.mp4\n",
      "[download] 100% of    3.88MiB in 00:00:22 at 177.76KiB/s                \n",
      "[ExtractAudio] Destination: songs\\Khoya Sitara - Dizlaw (Official music video) ｜ Azadi Records.mp3\n",
      "Deleting original file songs\\Khoya Sitara - Dizlaw (Official music video) ｜ Azadi Records.mp4 (pass -k to keep)\n",
      "[download] Downloading item 3 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=6Iox2oVm1sI\n",
      "[youtube] 6Iox2oVm1sI: Downloading webpage\n",
      "[youtube] 6Iox2oVm1sI: Downloading tv client config\n",
      "[youtube] 6Iox2oVm1sI: Downloading tv player API JSON\n",
      "[youtube] 6Iox2oVm1sI: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 6Iox2oVm1sI: Signature extraction failed: Some formats may be missing\n",
      "         player = https://www.youtube.com/s/player/e12fbea4/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] 6Iox2oVm1sI: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 6Iox2oVm1sI: Downloading m3u8 information\n",
      "[info] Testing format 234\n",
      "[info] 6Iox2oVm1sI: Downloading 1 format(s): 234\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 50\n",
      "[download] Destination: songs\\Bharg & @ChaarDiwaari  - Roshni ｜ Nikamma.mp4\n",
      "[download] 100% of    3.95MiB in 00:00:07 at 507.57KiB/s                \n",
      "[ExtractAudio] Destination: songs\\Bharg & @ChaarDiwaari  - Roshni ｜ Nikamma.mp3\n",
      "Deleting original file songs\\Bharg & @ChaarDiwaari  - Roshni ｜ Nikamma.mp4 (pass -k to keep)\n",
      "[download] Downloading item 4 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jj3AOSCEGp4\n",
      "[youtube] jj3AOSCEGp4: Downloading webpage\n",
      "[youtube] jj3AOSCEGp4: Downloading tv client config\n",
      "[youtube] jj3AOSCEGp4: Downloading tv player API JSON\n",
      "[youtube] jj3AOSCEGp4: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] jj3AOSCEGp4: Signature extraction failed: Some formats may be missing\n",
      "         player = https://www.youtube.com/s/player/e12fbea4/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] jj3AOSCEGp4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] jj3AOSCEGp4: Downloading m3u8 information\n",
      "[info] Testing format 234\n",
      "[info] jj3AOSCEGp4: Downloading 1 format(s): 234\n",
      "[hlsnative] Downloading m3u8 manifest\n",
      "[hlsnative] Total fragments: 41\n",
      "[download] Destination: songs\\Naksha.mp4\n",
      "[download] 100% of    3.21MiB in 00:00:16 at 195.13KiB/s                \n",
      "[ExtractAudio] Destination: songs\\Naksha.mp3\n",
      "Deleting original file songs\\Naksha.mp4 (pass -k to keep)\n",
      "[download] Downloading item 5 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=6pQcD3xKAtA\n",
      "[youtube] 6pQcD3xKAtA: Downloading webpage\n",
      "[youtube] 6pQcD3xKAtA: Downloading tv client config\n",
      "[youtube] 6pQcD3xKAtA: Downloading tv player API JSON\n",
      "[youtube] 6pQcD3xKAtA: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] 6pQcD3xKAtA: Video unavailable. This video is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Finished downloading playlist: idk\n"
     ]
    }
   ],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "ydt_opts={\n",
    "    'format': 'bestaudio/best',\n",
    "    'extractaudio': True,  # Download only audio\n",
    "    'audioformat': 'mp3',  # Save as mp3\n",
    "    'outtmpl': 'songs/%(title)s.%(ext)s',  # Save to songs folder with title as filename\n",
    "    'ignoreerrors': True,\n",
    "    'noplaylist': False,  # Make sure it's treated as a playlist\n",
    "\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "}\n",
    "\n",
    "playlist_url = 'https://www.youtube.com/playlist?list=PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg'\n",
    "\n",
    "with YoutubeDL(ydt_opts) as ydl:\n",
    "    ydl.download([playlist_url])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0c305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg\n",
      "[youtube:tab] PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] YouTube said: INFO - 1 unavailable video is hidden\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg: Redownloading playlist API JSON with unavailable videos\n",
      "[download] Downloading playlist: idk\n",
      "[youtube:tab] PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg page 1: Downloading API JSON\n",
      "[youtube:tab] Playlist idk: Downloading 5 items of 5\n",
      "[download] Downloading item 1 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=p0kKahGOKe8\n",
      "[youtube] p0kKahGOKe8: Downloading webpage\n",
      "[youtube] p0kKahGOKe8: Downloading tv client config\n",
      "[youtube] p0kKahGOKe8: Downloading tv player API JSON\n",
      "[youtube] p0kKahGOKe8: Downloading ios player API JSON\n",
      "[youtube] p0kKahGOKe8: Downloading m3u8 information\n",
      "[info] p0kKahGOKe8: Downloading 1 format(s): 251\n",
      "[download] Destination: p0kKahGOKe8.webm\n",
      "[download] 100% of    3.38MiB in 00:00:00 at 3.39MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: WARNING: unable to obtain file audio codec with ffprobe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Downloading item 2 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=2k7E3u36gt4\n",
      "[youtube] 2k7E3u36gt4: Downloading webpage\n",
      "[youtube] 2k7E3u36gt4: Downloading tv client config\n",
      "[youtube] 2k7E3u36gt4: Downloading tv player API JSON\n",
      "[youtube] 2k7E3u36gt4: Downloading ios player API JSON\n",
      "[youtube] 2k7E3u36gt4: Downloading m3u8 information\n",
      "[info] 2k7E3u36gt4: Downloading 1 format(s): 251\n",
      "[download] Destination: 2k7E3u36gt4.webm\n",
      "[download] 100% of    4.17MiB in 00:00:01 at 3.18MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: WARNING: unable to obtain file audio codec with ffprobe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Downloading item 3 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=6Iox2oVm1sI\n",
      "[youtube] 6Iox2oVm1sI: Downloading webpage\n",
      "[youtube] 6Iox2oVm1sI: Downloading tv client config\n",
      "[youtube] 6Iox2oVm1sI: Downloading tv player API JSON\n",
      "[youtube] 6Iox2oVm1sI: Downloading ios player API JSON\n",
      "[youtube] 6Iox2oVm1sI: Downloading m3u8 information\n",
      "[info] 6Iox2oVm1sI: Downloading 1 format(s): 251\n",
      "[download] Destination: 6Iox2oVm1sI.webm\n",
      "[download] 100% of    3.94MiB in 00:00:01 at 3.19MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: WARNING: unable to obtain file audio codec with ffprobe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Downloading item 4 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=jj3AOSCEGp4\n",
      "[youtube] jj3AOSCEGp4: Downloading webpage\n",
      "[youtube] jj3AOSCEGp4: Downloading tv client config\n",
      "[youtube] jj3AOSCEGp4: Downloading tv player API JSON\n",
      "[youtube] jj3AOSCEGp4: Downloading ios player API JSON\n",
      "[youtube] jj3AOSCEGp4: Downloading m3u8 information\n",
      "[info] jj3AOSCEGp4: Downloading 1 format(s): 251\n",
      "[download] Destination: jj3AOSCEGp4.webm\n",
      "[download] 100% of    3.57MiB in 00:00:00 at 4.13MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: WARNING: unable to obtain file audio codec with ffprobe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Downloading item 5 of 5\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=6pQcD3xKAtA\n",
      "[youtube] 6pQcD3xKAtA: Downloading webpage\n",
      "[youtube] 6pQcD3xKAtA: Downloading tv client config\n",
      "[youtube] 6pQcD3xKAtA: Downloading tv player API JSON\n",
      "[youtube] 6pQcD3xKAtA: Downloading ios player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] 6pQcD3xKAtA: Video unavailable. This video is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download] Finished downloading playlist: idk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "# Step 1: Create a valid filename function\n",
    "def clean_filename(name):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', \"\", name)\n",
    "\n",
    "# Step 2: Prepare metadata dictionary\n",
    "songs_meta = {}\n",
    "\n",
    "# Load existing metadata if present\n",
    "meta_file = \"songs_meta.json\"\n",
    "if os.path.exists(meta_file):\n",
    "    with open(meta_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        songs_meta = json.load(f)\n",
    "\n",
    "# Step 3: Define output directory\n",
    "output_dir = \"songs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Step 4: Define progress hook\n",
    "def progress_hook(d):\n",
    "    if d['status'] == 'finished':\n",
    "        info = d['info_dict']\n",
    "        title = info.get('title', 'Unknown Title')\n",
    "        artist = info.get('uploader', 'Unknown Artist')\n",
    "        video_id = info.get('id')\n",
    "        ext = info.get('ext', 'mp3')\n",
    "\n",
    "        safe_title = clean_filename(title)\n",
    "        filename = f\"{safe_title}.mp3\"\n",
    "        original_path = f\"{video_id}.{ext}\"\n",
    "        final_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        if os.path.exists(original_path):\n",
    "            os.rename(original_path, final_path)\n",
    "\n",
    "        # Add or update song metadata\n",
    "        songs_meta[safe_title] = {\n",
    "            \"title\": title,\n",
    "            \"artist\": artist,\n",
    "            \"location\": final_path\n",
    "        }\n",
    "\n",
    "# Step 5: Define YT-DLP options\n",
    "def get_yt_dlp_opts():\n",
    "    return {\n",
    "        'format': 'bestaudio/best',\n",
    "        'ignoreerrors': True,\n",
    "        'quiet': False,\n",
    "        'noplaylist': False,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'progress_hooks': [progress_hook],\n",
    "        'outtmpl': '%(id)s.%(ext)s',\n",
    "    }\n",
    "\n",
    "# Step 6: Start download\n",
    "playlist_url = \"https://www.youtube.com/playlist?list=PLwi5bnlaFJvgc7x1MPvV3h2KyU5vlVQKg\"\n",
    "\n",
    "with YoutubeDL(get_yt_dlp_opts()) as ydl:\n",
    "    ydl.download([playlist_url])\n",
    "\n",
    "# Step 7: Save updated metadata\n",
    "with open(meta_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(songs_meta, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
